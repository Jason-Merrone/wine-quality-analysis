{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36130d92-6205-493f-97d1-f21fcb07d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ec01ff1-2661-4bce-a4b7-a7d16593e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('winequality-white.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aded328f-fa5d-4888-8543-513f038e6435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  y  \n",
       "0         8.8        6  1  \n",
       "1         9.5        6  1  \n",
       "2        10.1        6  1  \n",
       "3         9.9        6  1  \n",
       "4         9.9        6  1  \n",
       "...       ...      ... ..  \n",
       "4893     11.2        6  1  \n",
       "4894      9.6        5  0  \n",
       "4895      9.4        6  1  \n",
       "4896     12.8        7  1  \n",
       "4897     11.8        6  1  \n",
       "\n",
       "[4898 rows x 13 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary target variable to analyze wine quality\n",
    "df['y'] =df['quality'].apply(lambda x: 0 if x <= 5 else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a12091df-1890-4bdc-ba0a-606650015bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33483054307880766, 0.6651694569211923)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class imbalance ratio\n",
    "zero_count = (df['y'] == 0).sum()\n",
    "one_count = (df['y'] == 1).sum()\n",
    "num_rows = len(df)\n",
    "\n",
    "proportion_zero = zero_count / num_rows\n",
    "proportion_one = one_count/ num_rows\n",
    "proportion_zero,proportion_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04baaa33-ad04-43bf-9d18-3216ce5105d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features and target using the updated dataset\n",
    "X = df.drop(['quality', 'y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Repeat the three-way stratified split: train (60%), validation (20%), test (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test,y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6173d68-15fd-46c5-a17b-befd6c851197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2f64203-7371-4d48-b908-d9a2f317b1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: (0.773469387755102, 0.7510204081632653, 0.753061224489796)\n",
      "precision: (0.8257575757575758, 0.7947976878612717, 0.8005865102639296)\n",
      "recall: (0.8358895705521472, 0.843558282208589, 0.8374233128834356)\n",
      "f1: (0.8307926829268293, 0.8184523809523809, 0.8185907046476761)\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "neighbors = [1,3,5]\n",
    "knn_metrics = []\n",
    "knn_models = []\n",
    "\n",
    "for n in neighbors:\n",
    "    # Train the model\n",
    "    knn  = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "\n",
    "    # Store predictions from validation set\n",
    "    y_pred = knn.predict(X_val_scaled)\n",
    "\n",
    "    # Record model prediction metrics\n",
    "    accuracy = accuracy_score(y_val,y_pred)\n",
    "    precision = precision_score(y_val,y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val,y_pred)\n",
    "    f1 = f1_score(y_val,y_pred)\n",
    "    knn_metrics.append([accuracy,precision,recall,f1])\n",
    "    knn_models.append(knn)\n",
    "\n",
    "print(f\"accuracy: {knn_metrics[0][0],knn_metrics[1][0],knn_metrics[2][0]}\")\n",
    "print(f\"precision: {knn_metrics[0][1],knn_metrics[1][1],knn_metrics[2][1]}\")\n",
    "print(f\"recall: {knn_metrics[0][2],knn_metrics[1][2],knn_metrics[2][2]}\")\n",
    "print(f\"f1: {knn_metrics[0][3],knn_metrics[1][3],knn_metrics[2][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "848379aa-409d-4333-a5e4-7ff975e96ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: (0.7612244897959184, 0.736734693877551, 0.726530612244898)\n",
      "precision: (0.7960339943342776, 0.7585301837270341, 0.7335766423357665)\n",
      "recall: (0.8619631901840491, 0.8865030674846626, 0.9248466257668712)\n",
      "f1: (0.8276877761413843, 0.8175388967468176, 0.8181818181818182)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = [\"rbf\",\"linear\",\"poly\"]\n",
    "svm_metrics = []\n",
    "svm_models = []\n",
    "\n",
    "for k in kernels:\n",
    "    # Train the model\n",
    "    svm = SVC(kernel=k)\n",
    "    svm.fit(X_train_scaled,y_train)\n",
    "\n",
    "    # Store predictions from validation set\n",
    "    y_pred = svm.predict(X_val_scaled)\n",
    "\n",
    "    # Record model prediction metrics\n",
    "    accuracy = accuracy_score(y_val,y_pred)\n",
    "    precision = precision_score(y_val,y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val,y_pred)\n",
    "    f1 = f1_score(y_val,y_pred)\n",
    "    svm_metrics.append([accuracy,precision,recall,f1])\n",
    "    svm_models.append(svm)\n",
    "\n",
    "print(f\"accuracy: {svm_metrics[0][0],svm_metrics[1][0],svm_metrics[2][0]}\")\n",
    "print(f\"precision: {svm_metrics[0][1],svm_metrics[1][1],svm_metrics[2][1]}\")\n",
    "print(f\"recall: {svm_metrics[0][2],svm_metrics[1][2],svm_metrics[2][2]}\")\n",
    "print(f\"f1: {svm_metrics[0][3],svm_metrics[1][3],svm_metrics[2][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "718611c9-96f7-4af7-9052-02f1052b8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: (0.7571428571428571, 0.7612244897959184)\n",
      "precision: (0.8244514106583072, 0.8225308641975309)\n",
      "recall: (0.8067484662576687, 0.8174846625766872)\n",
      "f1: (0.8155038759689922, 0.82)\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "criterion = [\"gini\",\"entropy\"]\n",
    "dtc_metrics = []\n",
    "dtc_models = []\n",
    "\n",
    "for c in criterion:\n",
    "    # Train the model\n",
    "    dtc = DTC(criterion=c)\n",
    "    dtc.fit(X_train_scaled,y_train)\n",
    "\n",
    "    # Store predictions from validation set\n",
    "    y_pred = dtc.predict(X_val_scaled)\n",
    "\n",
    "    # Record model prediction metrics\n",
    "    accuracy = accuracy_score(y_val,y_pred)\n",
    "    precision = precision_score(y_val,y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val,y_pred)\n",
    "    f1 = f1_score(y_val,y_pred)\n",
    "    dtc_metrics.append([accuracy,precision,recall,f1])\n",
    "    dtc_models.append(dtc)\n",
    "\n",
    "print(f\"accuracy: {dtc_metrics[0][0],dtc_metrics[1][0]}\")\n",
    "print(f\"precision: {dtc_metrics[0][1],dtc_metrics[1][1]}\")\n",
    "print(f\"recall: {dtc_metrics[0][2],dtc_metrics[1][2]}\")\n",
    "print(f\"f1: {dtc_metrics[0][3],dtc_metrics[1][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f4a6eebc-f740-40e0-9872-16afaf8e3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: (0.7336734693877551, 0.7336734693877551)\n",
      "precision: (0.7603195739014648, 0.7603195739014648)\n",
      "recall: (0.8757668711656442, 0.8757668711656442)\n",
      "f1: (0.8139700641482538, 0.8139700641482538)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "penalties = [\"l1\",\"l2\"]\n",
    "lReg_metrics = []\n",
    "lReg_models = []\n",
    "\n",
    "for p in penalties:\n",
    "    # Train the model\n",
    "    lReg = LogisticRegression(penalty=p, solver='liblinear', random_state = 42)\n",
    "    lReg.fit(X_train_scaled,y_train)\n",
    "\n",
    "    # Store predictions from validation set\n",
    "    y_pred = lReg.predict(X_val_scaled)\n",
    "\n",
    "    # Record model prediction metrics\n",
    "    accuracy = accuracy_score(y_val,y_pred)\n",
    "    precision = precision_score(y_val,y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val,y_pred)\n",
    "    f1 = f1_score(y_val,y_pred)\n",
    "    lReg_metrics.append([accuracy,precision,recall,f1])\n",
    "    lReg_models.append(lReg)\n",
    "\n",
    "print(f\"accuracy: {lReg_metrics[0][0],lReg_metrics[1][0]}\")\n",
    "print(f\"precision: {lReg_metrics[0][1],lReg_metrics[1][1]}\")\n",
    "print(f\"recall: {lReg_metrics[0][2],lReg_metrics[1][2]}\")\n",
    "print(f\"f1: {lReg_metrics[0][3],lReg_metrics[1][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f637cc79-835f-4ec2-82cf-8ac010c048fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kNN (n_neighbors = [1, 3, 5])</th>\n",
       "      <td>0.773469387755102, 0.7510204081632653, 0.75306...</td>\n",
       "      <td>0.8257575757575758, 0.7947976878612717, 0.8005...</td>\n",
       "      <td>0.8358895705521472, 0.843558282208589, 0.83742...</td>\n",
       "      <td>0.8307926829268293, 0.8184523809523809, 0.8185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM (kernel = [rbf, linear, poly])</th>\n",
       "      <td>0.7612244897959184, 0.736734693877551, 0.72653...</td>\n",
       "      <td>0.7960339943342776, 0.7585301837270341, 0.7335...</td>\n",
       "      <td>0.8619631901840491, 0.8865030674846626, 0.9248...</td>\n",
       "      <td>0.8276877761413843, 0.8175388967468176, 0.8181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree (criterion = [gini, entropy])</th>\n",
       "      <td>0.7571428571428571, 0.7612244897959184</td>\n",
       "      <td>0.8244514106583072, 0.8225308641975309</td>\n",
       "      <td>0.8067484662576687, 0.8174846625766872</td>\n",
       "      <td>0.8155038759689922, 0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression (penalty = [l1, l2])</th>\n",
       "      <td>0.733673</td>\n",
       "      <td>0.76032</td>\n",
       "      <td>0.875767</td>\n",
       "      <td>0.81397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Accuracy  \\\n",
       "Classifier                                                                                       \n",
       "kNN (n_neighbors = [1, 3, 5])                0.773469387755102, 0.7510204081632653, 0.75306...   \n",
       "SVM (kernel = [rbf, linear, poly])           0.7612244897959184, 0.736734693877551, 0.72653...   \n",
       "Decision tree (criterion = [gini, entropy])             0.7571428571428571, 0.7612244897959184   \n",
       "Logistic regression (penalty = [l1, l2])                                              0.733673   \n",
       "\n",
       "                                                                                     Precision  \\\n",
       "Classifier                                                                                       \n",
       "kNN (n_neighbors = [1, 3, 5])                0.8257575757575758, 0.7947976878612717, 0.8005...   \n",
       "SVM (kernel = [rbf, linear, poly])           0.7960339943342776, 0.7585301837270341, 0.7335...   \n",
       "Decision tree (criterion = [gini, entropy])             0.8244514106583072, 0.8225308641975309   \n",
       "Logistic regression (penalty = [l1, l2])                                               0.76032   \n",
       "\n",
       "                                                                                        Recall  \\\n",
       "Classifier                                                                                       \n",
       "kNN (n_neighbors = [1, 3, 5])                0.8358895705521472, 0.843558282208589, 0.83742...   \n",
       "SVM (kernel = [rbf, linear, poly])           0.8619631901840491, 0.8865030674846626, 0.9248...   \n",
       "Decision tree (criterion = [gini, entropy])             0.8067484662576687, 0.8174846625766872   \n",
       "Logistic regression (penalty = [l1, l2])                                              0.875767   \n",
       "\n",
       "                                                                                            F1  \n",
       "Classifier                                                                                      \n",
       "kNN (n_neighbors = [1, 3, 5])                0.8307926829268293, 0.8184523809523809, 0.8185...  \n",
       "SVM (kernel = [rbf, linear, poly])           0.8276877761413843, 0.8175388967468176, 0.8181...  \n",
       "Decision tree (criterion = [gini, entropy])                           0.8155038759689922, 0.82  \n",
       "Logistic regression (penalty = [l1, l2])                                               0.81397  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to display the results as a table\n",
    "metrics_data = {\n",
    "    'Classifier': ['kNN (n_neighbors = [1, 3, 5])', 'SVM (kernel = [rbf, linear, poly])', \n",
    "                   'Decision tree (criterion = [gini, entropy])', 'Logistic regression (penalty = [l1, l2])'],\n",
    "    'Accuracy': [knn_metrics[0][0], svm_metrics[0][0], dtc_metrics[0][0], lReg_metrics[0][0]],\n",
    "    'Precision': [knn_metrics[0][1], svm_metrics[0][1], dtc_metrics[0][1], lReg_metrics[0][1]],\n",
    "    'Recall': [knn_metrics[0][2], svm_metrics[0][2], dtc_metrics[0][2], lReg_metrics[0][2]],\n",
    "    'F1': [knn_metrics[0][3], svm_metrics[0][3], dtc_metrics[0][3], lReg_metrics[0][3]]\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(1, 3):\n",
    "    metrics_data['Accuracy'][0] = f\"{metrics_data['Accuracy'][0]}, {knn_metrics[i][0]}\"\n",
    "    metrics_data['Precision'][0] = f\"{metrics_data['Precision'][0]}, {knn_metrics[i][1]}\"\n",
    "    metrics_data['Recall'][0] = f\"{metrics_data['Recall'][0]}, {knn_metrics[i][2]}\"\n",
    "    metrics_data['F1'][0] = f\"{metrics_data['F1'][0]}, {knn_metrics[i][3]}\"\n",
    "    metrics_data['Accuracy'][1] = f\"{metrics_data['Accuracy'][1]}, {svm_metrics[i][0]}\"\n",
    "    metrics_data['Precision'][1] = f\"{metrics_data['Precision'][1]}, {svm_metrics[i][1]}\"\n",
    "    metrics_data['Recall'][1] = f\"{metrics_data['Recall'][1]}, {svm_metrics[i][2]}\"\n",
    "    metrics_data['F1'][1] = f\"{metrics_data['F1'][1]}, {svm_metrics[i][3]}\"\n",
    "\n",
    "    if i < 2:  # For SVM and Decision Tree, we only have two configurations\n",
    "        metrics_data['Accuracy'][2] = f\"{metrics_data['Accuracy'][2]}, {dtc_metrics[i][0]}\"\n",
    "        metrics_data['Precision'][2] = f\"{metrics_data['Precision'][2]}, {dtc_metrics[i][1]}\"\n",
    "        metrics_data['Recall'][2] = f\"{metrics_data['Recall'][2]}, {dtc_metrics[i][2]}\"\n",
    "        metrics_data['F1'][2] = f\"{metrics_data['F1'][2]}, {dtc_metrics[i][3]}\"\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "df_metrics.set_index('Classifier', inplace=True)\n",
    "df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40225e89-1aa6-42a6-9637-fe9be5081eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('kNN', 0, 0.8307926829268293)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for finding the model with the best F1 score\n",
    "def find_best_model_by_f1(knn_metrics, svm_metrics, dtc_metrics, lReg_metrics):\n",
    "    # Combine all metrics into one list\n",
    "    all_metrics = [\n",
    "        ('kNN', knn_metrics),\n",
    "        ('SVM', svm_metrics),\n",
    "        ('Decision Tree', dtc_metrics),\n",
    "        ('Logistic Regression', lReg_metrics)]\n",
    "\n",
    "    # Keep track of the best model\n",
    "    best_f1_score = -1\n",
    "    best_model = None\n",
    "    best_config = None\n",
    "    \n",
    "    for model_name, metrics in all_metrics:\n",
    "        for i, (accuracy, precision, recall, f1) in enumerate(metrics):\n",
    "            if f1 > best_f1_score:\n",
    "                best_f1_score = f1\n",
    "                best_model = model_name\n",
    "                best_config = i\n",
    "    return best_model, best_config, best_f1_score\n",
    "\n",
    "best_model, best_config, best_f1_score = find_best_model_by_f1(knn_metrics, svm_metrics, dtc_metrics, lReg_metrics)\n",
    "\n",
    "# The model with the best f1 will be tested\n",
    "model_to_test = []\n",
    "if(best_model == 'kNN'):\n",
    "    if(best_config == 0):\n",
    "        model_to_test = knn_models[0]\n",
    "    elif (best_config == 1):\n",
    "        model_to_test = knn_models[1]\n",
    "    else:\n",
    "        model_to_test = knn_models[2]\n",
    "\n",
    "elif(best_model == 'SVM'):\n",
    "    if(best_config == 0):\n",
    "        model_to_test = svm_models[0]\n",
    "    elif (best_config == 1):\n",
    "        model_to_test = svm_models[1]\n",
    "    else:\n",
    "        model_to_test = svm_models[2]\n",
    "\n",
    "elif(best_model == 'Decision Tree'):\n",
    "    if(best_config == 0):\n",
    "        model_to_test = dtc_models[0]\n",
    "    elif (best_config == 1):\n",
    "        model_to_test = dtc_models[1]\n",
    "    else:\n",
    "        model_to_test = dtc_models[2]\n",
    "else:\n",
    "    if(best_config == 0):\n",
    "        model_to_test = lReg_models[0]\n",
    "    elif (best_config == 1):\n",
    "        model_to_test = lReg_models[1]\n",
    "    else:\n",
    "        model_to_test = lReg_models[2]\n",
    "best_model, best_config, best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d29cf56a-475f-4c9e-b8ce-79724862e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:[[212 116]\n",
      " [118 534]]\n",
      "Accuracy:0.7612244897959184\n",
      "Precision:0.8215384615384616\n",
      "Recall:0.8190184049079755\n",
      "f1:0.8202764976958525\n"
     ]
    }
   ],
   "source": [
    "# Analysis of best model using test data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_pred = model_to_test.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Confusion Matrix:{conf_matrix}\")\n",
    "print(f\"Accuracy:{test_accuracy}\")\n",
    "print(f\"Precision:{test_precision}\")\n",
    "print(f\"Recall:{test_recall}\")\n",
    "print(f\"f1:{test_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
